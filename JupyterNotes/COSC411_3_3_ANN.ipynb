{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf800741",
   "metadata": {},
   "source": [
    "# COSC 411: Artificial Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6eba9e",
   "metadata": {},
   "source": [
    "Instructor: Dr. Shuangquan (Peter) Wang\n",
    "\n",
    "Email: spwang@salisbury.edu\n",
    "\n",
    "Department of Computer Science, Salisbury University\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1c799d",
   "metadata": {},
   "source": [
    "# Module 3_ML algorithms and application\n",
    "\n",
    "## 3. Artificial Neural Networks (ANN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2f5141",
   "metadata": {},
   "source": [
    "**Contents of this note are mainly from 1) Dr.Robert Michael Lewis's teaching materials at Department of Computer Science, William & Mary; and 2) https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e961abf6",
   "metadata": {},
   "source": [
    "**<font color=red>All rights reserved. Dissemination or sale of any part of this note is NOT permitted.</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2667fa8f",
   "metadata": {},
   "source": [
    "# Artificial neural networks\n",
    "\n",
    "**Artificial neural networks (ANN)**, also called **multilayer perceptrons (MLP)** or neural networks, for short, are an elaboration of the perceptron we have seen previously.\n",
    "\n",
    "ANNs are characterized by a large number of relatively simple, parallel computations being combined to approximate complex input-output relationships.\n",
    "\n",
    "**The input-output relationships ANNs model are not restricted to classification.**\n",
    "\n",
    "In classification, we have the input-output relationship\n",
    "$$\n",
    "\\mbox{features} \\longrightarrow \\mbox{class label}.\n",
    "$$\n",
    "\n",
    "More generally we can imagine a generic input-output relationship\n",
    "$$\n",
    "\\mbox{features $x$} \\longrightarrow \\mbox{output $y = F(x)$}.\n",
    "$$\n",
    "\n",
    "Fitting models to general input-output relationships is broadly known as **regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b04053d",
   "metadata": {},
   "source": [
    "## When are ANNs appropriate?\n",
    "\n",
    "* There is an input-output relationship we wish to model with many attribute-value pairs.  Inputs can be any real numerical values.\n",
    "* The target output is one or more discrete values or real values.\n",
    "* The training set may contain noise.  ANN learning methods are robust with respect to noise in the training set (provided you avoid overfitting!).\n",
    "* Long model calibration times are acceptable.  Training an ANN is typically a more computationally intensive task than constructing a decision tree, for instance.\n",
    "* Fast evaluation of the input-output function is desirable.  While training an ANN takes time, applying it to new cases is very fast.\n",
    "* An opaque model is acceptable.  ANNs are frequently difficult to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331ca5b2",
   "metadata": {},
   "source": [
    "# Multilayer networks\n",
    "\n",
    "To overcome the limitations of a single perceptron, we need a network of perceptron-like units.\n",
    "\n",
    "The building blocks of the multilayer ANN will be functions of the form\n",
    "$$\n",
    "o(x_{1}, \\ldots, x_{n}) = \\sigma(w^{T}x).\n",
    "$$\n",
    "\n",
    "The original perceptron is a discontinuous function of its inputs.  It is more convenient to have a differentiable function.  A standard choice is the sigmoid function (a.k.a. the logistic function)\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1+e^{-z}}.\n",
    "$$\n",
    "Its output ranges between 0 and 1.\n",
    "\n",
    "Other common choices are \n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1+e^{-kz}},\\quad k > 0\n",
    "$$\n",
    "The function $\\sigma$ is called the **activation function**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd42a93",
   "metadata": {},
   "source": [
    "# ANNs in scikit-learn\n",
    "\n",
    "Let's look at an example using the ANN in scikit-learn, the [MLP class](http://scikit-learn.org/stable/modules/neural_networks_supervised.html).\n",
    "\n",
    "We will use an ANN to model the input-output relationship $y = \\sqrt{x}$.\n",
    "\n",
    "This is **not** a classification problem.  It is a regression problem.\n",
    "\n",
    "We will create an ANN with\n",
    "* a single input, $x$, \n",
    "* a single hidden layer with 10 nodes, and\n",
    "* a single output, the estimate of $\\sqrt{x}$.\n",
    "\n",
    "For unit $i$ in the hidden layer, the ANN takes $x$ and maps it to $w_{0,i} + w_{1,i}x$ and feeds it to the activation function for unit $i$.\n",
    "\n",
    "This means there are 20 model parameters for the map from the inputs to the hidden layer: the weights $w_{0,i}$ and the weight $w_{1,i}$ for each unit in the hidden layer.\n",
    "\n",
    "There are also 11 weights that take the hidden layer outputs and map them to the final scalar output.\n",
    "\n",
    "Thus, there is a total of 31 model parameter.\n",
    "\n",
    "We will create a training set of 200 equally spaced values of $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56896bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Here is the training set.\n",
    "X_train = np.linspace(0, 10, 200)\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "y_train = np.sqrt(X_train)\n",
    "y_train = y_train.ravel()\n",
    "\n",
    "plt.plot(X_train, y_train, 'b-')\n",
    "plt.title('Plot of $y = \\sqrt{x}$', fontsize=18)\n",
    "\n",
    "ann = MLPRegressor(solver='lbfgs', alpha=1e-5, activation='relu',\n",
    "                   hidden_layer_sizes=(10), random_state=1)\n",
    "\n",
    "ann.fit(X_train, y_train)                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0d01fc",
   "metadata": {},
   "source": [
    "Now create a test set of 20 uniformly distributed random variables in the interval [0, 10] and use the ANN to predict the values of their square root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4949a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = 10*np.random.rand(20, 1)\n",
    "y_test = np.sqrt(X_test)\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6494058",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_train, y_train, 'b-', X_test, y_pred, 'ro')\n",
    "plt.title('ANN predictions in red', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89f1561",
   "metadata": {},
   "source": [
    "Now let's look at the model coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71884942",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ann.coefs_\n",
    "b = ann.intercepts_\n",
    "\n",
    "print('coefficients for inputs to hidden layer: ')\n",
    "print(c[0])\n",
    "print('intercepts (weight 0) for inputs to hidden layer:')\n",
    "print(b[0])\n",
    "print()\n",
    "\n",
    "print('coeffcients for hidden layer to output:')\n",
    "print(c[1])\n",
    "print('intercept (weight 0) for hidden layer to output:')\n",
    "print(b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e36bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a720bc9f",
   "metadata": {},
   "source": [
    "\n",
    "# Recognizing hand-written digits\n",
    "\n",
    "This example shows how ANN can be used to recognize images of hand-written digits, from 0-9.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b951d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revised from the following example\n",
    "# Author: Gael Varoquaux <gael dot varoquaux at normalesup dot org>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4033609",
   "metadata": {},
   "source": [
    "## Digits dataset\n",
    "\n",
    "The digits dataset consists of 8x8\n",
    "pixel images of digits. The ``images`` attribute of the dataset stores\n",
    "8x8 arrays of grayscale values for each image. We will use these arrays to\n",
    "visualize the first 4 images. The ``target`` attribute of the dataset stores\n",
    "the digit each image represents and this is included in the title of the 4\n",
    "plots below.\n",
    "\n",
    "Note: if we were working from image files (e.g., 'png' files), we would load\n",
    "them using `matplotlib.pyplot.imread`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12393cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Training: %i\" % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b794ee",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "To apply ANN on this data, we need to flatten the images, turning\n",
    "each 2-D array of grayscale values from shape ``(8, 8)`` into shape\n",
    "``(64,)``. Subsequently, the entire dataset will be of shape\n",
    "``(n_samples, n_features)``, where ``n_samples`` is the number of images and\n",
    "``n_features`` is the total number of pixels in each image.\n",
    "\n",
    "We can then split the data into train and test subsets and fit an ANN classifier on the train samples. The fitted classifier can\n",
    "subsequently be used to predict the value of the digit for the samples\n",
    "in the test subset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b461408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the images\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Create a classifier\n",
    "ann = MLPClassifier(solver='lbfgs', alpha=1e-4, activation= \"logistic\",\n",
    "                    hidden_layer_sizes=(100), max_iter = 1000, random_state=1)\n",
    "\n",
    "# Split data into 50% train and 50% test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, digits.target, test_size=0.5, shuffle=False\n",
    ")\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "ann.fit(X_train, y_train)\n",
    "\n",
    "# Predict the value of the digit on the test subset\n",
    "predicted = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1208ed73",
   "metadata": {},
   "source": [
    "Below we visualize the first 4 test samples and show their predicted\n",
    "digit value in the title.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb14500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, prediction in zip(axes, X_test, predicted):\n",
    "    ax.set_axis_off()\n",
    "    image = image.reshape(8, 8)\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2c8edb",
   "metadata": {},
   "source": [
    "`sklearn.metrics.classification_report` builds a text report showing\n",
    "the main classification metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82044e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Classification report for classifier {ann}:\\n\"\n",
    "    f\"{metrics.classification_report(y_test, predicted)}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578e8619",
   "metadata": {},
   "source": [
    "We can also plot a `confusion matrix <confusion_matrix>` of the\n",
    "true digit values and the predicted digit values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786124cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, predicted)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "print(f\"Confusion matrix:\\n{disp.confusion_matrix}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c28077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
